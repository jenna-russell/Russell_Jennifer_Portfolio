{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set 2: Naive Bayes classification\n",
    "\n",
    "Can you tell whether a review of a restaurant is positive or negative? What words are most indicative? We'll examine data from Yelp to answer this problem quantitatively, provided as part of the Yelp Academic Challenge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we will create a program (a classifier) that uses actual examples of one-star and five-star reviews to classify text as positive or negative.  In particular, this classifier will estimate the probability that a review is negative or positive based on the words in that review and assign the most likely label (negative or positive).\n",
    "\n",
    "To do this, we will begin by partioning our collection of pre-labeled restaurant reviews into two sets, positive reviews and negative reviews. We will then count the relative frequency of each distinct word in the two sub-collections which will allow us to estimate the probability that a given word appears in a review given its polarity (positive or negatiev). These individual word probabilites will then be multiplied to etimate the probability of multiple words appearing in a  document given its polarity. Finally, we can then appply Bayes theorem to switch our conditionals: i.e. to estimate the probability a review is positive or negative based on the words in it.\n",
    "\n",
    "Here's the math. The first line is an application of Bayes' rule. The second line expands the marginal probability of the words into the sum over positive and negative polarities. The third line adds the \"naive\" assumption that words are independent, as long as we know the polarity. (Note that I flipped the order of the prior probability and the word probability in the third line, to make it clear where the product ends.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "P(positive|w_1, w_2, w_3, ..., w_N) & = \\frac{P(w_1, w_2, w_3, ..., w_N | positive)P(positive)}{P(w_1, w_2, w_3, ..., w_N)} \\\\\n",
    "&= \\frac{P(w_1, w_2, w_3, ..., w_N | positive)P(positive)}{P(w_1, w_2, w_3, ..., w_N | positive)P(positive) + P(w_1, w_2, w_3, ..., w_N | negative)P(negative)} \\\\\n",
    "&\\approx \\frac{P(positive)\\prod_i P(w_i|positive)}{P(positive)\\prod_i P(w_i|positive) + P(negative)\\prod_i P(w_i|negative) }\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to count the words in each of the two *training* sub-collections. They are in two files, `positive.txt` and `negative.txt`. Each line in these files is one review. Before we start, we need to decide how we are going to break reviews into words.\n",
    "\n",
    "Lets create a regular expression that matches sequences of one or more letter characters. Then write a short sentence and use the `findall` function to list all of the substrings of that sentence that match your pattern. Include at least one common word in your sentence that will not be handled well by this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'my',\n",
       " 'test',\n",
       " 'but',\n",
       " 'I',\n",
       " 'trés',\n",
       " 'don',\n",
       " 't',\n",
       " 'really',\n",
       " 'like',\n",
       " 'it']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read the two files, create counters\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "word_pattern = re.compile(\"\\w+\")\n",
    "\n",
    "word_pattern.findall(\"this is my test, but I trés don't really like it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply Bayes' rule to estimate the probability of polarity given a review, we need the probability of words given polarity and the probability of positive or negative polarity.\n",
    "\n",
    "First create variables that will store this information.\n",
    "For the positive reviews create a `Counter` that will store the counts of words in positive reviews. Also create a variable that will count the number of positive reviews. Create similar variables for the negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_counts = Counter()\n",
    "positive_reviews = 0\n",
    "negative_counts = Counter()\n",
    "negative_reviews = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read the two files, collecting the count of each distinct word in each sub-collection, as well as the number of reviews in each sub-collection. You will need to *update* the appropriate `Counter` for each review.\n",
    "\n",
    "Once you have processed the two files, test the counters by printing the five most common words in each counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 16168), ('and', 15149), ('I', 12937), ('a', 10532), ('to', 9411)]\n",
      "[('the', 6275), ('I', 5076), ('and', 4483), ('to', 4348), ('a', 3326)]\n"
     ]
    }
   ],
   "source": [
    "with open(\"positive.txt\", \"r\") as pos_reader:\n",
    "    for line in pos_reader:\n",
    "        positive_counts.update(word_pattern.findall(line))\n",
    "        positive_reviews += 1\n",
    "\n",
    "with open(\"negative.txt\", \"r\") as neg_reader:\n",
    "    for line in neg_reader:\n",
    "        negative_counts.update(word_pattern.findall(line))\n",
    "        negative_reviews += 1\n",
    "\n",
    "print(positive_counts.most_common(5))\n",
    "print(negative_counts.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the probability that a randomly selected review is positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8026043819760231"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews / (positive_reviews + negative_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this value surprise you? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two variables, `positive_tokens` and `negative_tokens`, whose value is the total number of word tokens in that sub-collection. Print these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415727 153876\n"
     ]
    }
   ],
   "source": [
    "positive_tokens = sum(positive_counts.values())\n",
    "negative_tokens = sum(negative_counts.values())\n",
    "\n",
    "print(positive_tokens, negative_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function `word_prob` that takes three arguments: a word, a counter, and a sum. It should return the probability of the word estimated from that counter. Assume that the sum is accurate, you don't need to check for errors.\n",
    "\n",
    "Use this function to print the probability of the words \"delicious\", \"manager\", \"edgy\", and \"vile\" in both sub-collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001282091372463179\n",
      "5.8488653201278955e-05\n",
      "0.00016837972996702164\n",
      "0.0011047856715797136\n",
      "4.810849427629189e-06\n",
      "0.0\n",
      "0.0\n",
      "6.498739244586551e-06\n"
     ]
    }
   ],
   "source": [
    "def word_prob(word, counter, total):\n",
    "    return counter[word] / total\n",
    "\n",
    "print(word_prob(\"delicious\", positive_counts, positive_tokens))\n",
    "print(word_prob(\"delicious\", negative_counts, negative_tokens))\n",
    "print(word_prob(\"manager\", positive_counts, positive_tokens))\n",
    "print(word_prob(\"manager\", negative_counts, negative_tokens))\n",
    "print(word_prob(\"edgy\", positive_counts, positive_tokens))\n",
    "print(word_prob(\"edgy\", negative_counts, negative_tokens))\n",
    "print(word_prob(\"vile\", positive_counts, positive_tokens))\n",
    "print(word_prob(\"vile\", negative_counts, negative_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a function `review_prob` that takes a string containing multiple words (for example \"the food was delicious\"), a counter, and a sum. It should use the same regular expression method you used when reading the files earlier to break this string into tokens, and then use `word_prob` to calculate the probability of each of those word tokens. It should then return the product of those probabilities.\n",
    "\n",
    "Print the probability of \"I loved the carnitas\", \"but then the manager came out and told us\", and \"the ambience was edgy but the food was vile\" according to both sub-collections. What do you notice about these six probabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2254483237140511e-11\n",
      "5.113217890059061e-13\n",
      "9.508351338741093e-25\n",
      "2.4727715407612935e-22\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def review_prob(review, counter, total):\n",
    "    prob = 1.0\n",
    "    for word in word_pattern.findall(review):\n",
    "        prob *= word_prob(word, counter, total)\n",
    "    return prob\n",
    "\n",
    "print(review_prob(\"I loved the carnitas\", positive_counts, positive_tokens))\n",
    "print(review_prob(\"I loved the carnitas\", negative_counts, negative_tokens))\n",
    "print(review_prob(\"but then the manager came out and told us\", positive_counts, positive_tokens))\n",
    "print(review_prob(\"but then the manager came out and told us\", negative_counts, negative_tokens))\n",
    "print(review_prob(\"the ambience was edgy but the food was vile\", positive_counts, positive_tokens))\n",
    "print(review_prob(\"the ambience was edgy but the food was vile\", negative_counts, negative_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your observations about the six probabilities here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of multiplying probabilities, we can also add *log* probabilities. Create a function `word_log_prob` that calculates the log probability of a word, and a function `review_log_prob` that calculates the sum of the log probabilities of the words in a string. These should take the same arguments as the previous functions.\n",
    "\n",
    "Print the log probabilities of the same example words and sentences from the previous problems. Explain any errors that occur in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-25.125129267349543\n",
      "-28.301777278817983\n"
     ]
    }
   ],
   "source": [
    "import math  ## watch for errors from not importing math\n",
    "\n",
    "def word_log_prob(word, counter, total):\n",
    "    return math.log(counter[word] / total)\n",
    "\n",
    "def review_log_prob(review, counter, total):\n",
    "    log_prob = 0.0\n",
    "    for word in word_pattern.findall(review):\n",
    "        log_prob += word_log_prob(word, counter, total)\n",
    "    return log_prob\n",
    "\n",
    "print(review_log_prob(\"I loved the carnitas\", positive_counts, positive_tokens))\n",
    "print(review_log_prob(\"I loved the carnitas\", negative_counts, negative_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a word type never occurs in our negative reviews, it will have probability zero. But we don't want to rule out the possibility that any future negative review could include that word type. We need to a way to give non-zero probability in both positive and negative polarities to a word that we have only seen in one. A simple way to do this is to add 1 to the count when we calculate word probability, as long as the word has appeared in at least one sub-collection (words we have never seen in either sub-collection will still have probability zero).\n",
    "\n",
    "This change avoids log-zero errors, but it violates the laws of probability. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `Counter` called `both_counts` by adding the two negative and positive counters together (just use +, Counters are awesome). Create a new variable `both_tokens` to represent the total number of tokens in the collection. Create a variable `vocabulary_size` whose value is the total number of distinct word types in the collection. Print the vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24773\n"
     ]
    }
   ],
   "source": [
    "both_counts = positive_counts + negative_counts\n",
    "both_tokens = sum(both_counts.values())\n",
    "vocabulary_size = len(both_counts.keys())\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a function `smoothed_word_log_prob` that takes the same arguments as `word_prob` (word, counter, sum of the counter), but adds 1 to the count for the word (don't modify the counter, just add 1 in your function). Previously we divided the word count by the sum of all the counts in the counter, which guaranteed that the sum of the probability of all word types was 1.0. Now that we are adding 1 to each word, what should the denominator be so that this new probability distribution will sum to 1.0?\n",
    "\n",
    "Use this function to print the probability of the words \"delicious\", \"manager\", \"edgy\", and \"vile\" in both sub-collections. (These function calls should have the exact same arguments as the previous blocks.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-61.24505462122342\n",
      "-61.32258171744834\n"
     ]
    }
   ],
   "source": [
    "def smoothed_word_log_prob(word, counter, total):\n",
    "    ## Make sure they use parens here\n",
    "    return math.log((counter[word] + 1) / (total + vocabulary_size))\n",
    "\n",
    "def smoothed_review_log_prob(review, counter, total):\n",
    "    log_prob = 0.0\n",
    "    for word in word_pattern.findall(review):\n",
    "        log_prob += smoothed_word_log_prob(word, counter, total)\n",
    "    return log_prob\n",
    "\n",
    "print(smoothed_review_log_prob(\"the ambience was edgy but the food was vile\", positive_counts, positive_tokens))\n",
    "print(smoothed_review_log_prob(\"the ambience was edgy but the food was vile\", negative_counts, negative_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put it all together. Given a review, we want to know whether that review is more likely to be positive or negative. To answer this question we will calculate the log of the ratio between $P(positive | words\\ in\\ review)$ and $P(negative | words\\ in\\ review)$. This ratio is simpler than the two individual. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate this ratio for the review \"the ambience was edgy but the food was disgusting\". Use the probability that a review is positive or negative that you calculated earlier as the prior probabilities $P(positive)$ and $P(negative)$, but this time use the log of those probabilities. Print the resulting log probability ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-60.078653621541825\n",
      "-60.20428704421238\n"
     ]
    }
   ],
   "source": [
    "pos_log_like = smoothed_review_log_prob(\"the ambience was edgy but the food was disgusting\", positive_counts, positive_tokens)\n",
    "neg_log_like = smoothed_review_log_prob(\"the ambience was edgy but the food was disgusting\", negative_counts, negative_tokens)\n",
    "\n",
    "print(pos_log_like +  math.log(positive_reviews / (positive_reviews + negative_reviews)))\n",
    "print(neg_log_like + math.log(negative_reviews / (positive_reviews + negative_reviews)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How should you interpret the log probability ratio?\n",
    "* Which category is more likely?\n",
    "* Does the prior probability matter?\n",
    "* Suggest a prior probability that would change our decision, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
